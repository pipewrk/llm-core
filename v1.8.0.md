# v1.8.0 (2025-09-16)

## Breaking Changes
- `env` module removed from public exports; rely on `createOpenAIContext` / `createOllamaContext` and bound service factories instead.
- `prompts` types temporarily removed from exports pending redesign (will return in a future release under a stabilized schema interface).

## Features
- Export OpenAI Batch pipeline helpers and types: `fromArray`, `fromAsync`, `createJob`, `runBatch`, `tickBatch`, plus `BatchEnv`, `BatchJob`, `BatchState`, `ResumeToken`.

## Refactors
- Consolidated public type surface; internal modules (`env`, decorators, file-utils, ufetch, classification-service, ml-service) excluded from generated export map.
- Documentation updates (README, PIPELINE, OLLAMA_SERVICE) to reflect helper-focused usage and internalization of low-level env utilities.

## Migration Guide
- Replace any direct `import { getEnv } from '@jasonnathan/llm-core'` with context helpers:
  ```ts
  import { createOpenAIContext, createOpenAIService } from '@jasonnathan/llm-core';
  const ctx = createOpenAIContext({ openai: { model: 'gpt-4o-mini' } });
  const openai = createOpenAIService(ctx);
  ```
- For Ollama:
  ```ts
  import { createOllamaContext, createOllamaService } from '@jasonnathan/llm-core';
  const ctx = createOllamaContext({ ollama: { model: 'llama3:8b-instruct-q8_0' } });
  const ollama = createOllamaService(ctx);
  ```
- Batch pipelines: import from `@jasonnathan/llm-core/batch-openai-pipeline` (types now public). Existing internal prototypes should switch to `runBatch` / `tickBatch`.

